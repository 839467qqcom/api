# -*- coding: utf-8 -*-
"""
å¹¶å‘æ‰§è¡Œå¼•æ“ - æ”¯æŒæ–‡ä»¶çº§å¹¶å‘æ‰§è¡Œæµ‹è¯•ç”¨ä¾‹
"""
import os
import sys
import time
import shutil
import subprocess
from pathlib import Path
from concurrent.futures import ProcessPoolExecutor, as_completed
from typing import List, Dict, Any
import json

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from setup_paths import init_paths
init_paths()


class FileSelector:
    """æµ‹è¯•æ–‡ä»¶é€‰æ‹©å™¨"""
    
    def __init__(self, env: str):
        """
        åˆå§‹åŒ–æ–‡ä»¶é€‰æ‹©å™¨
        :param env: å½“å‰ç¯å¢ƒåç§°
        """
        self.env = env
        # ğŸ”§ ä½¿ç”¨é¡¹ç›®æ ¹ç›®å½•è·¯å¾„ï¼Œç¡®ä¿è·¯å¾„æ­£ç¡®
        project_root = Path(__file__).parent.parent  # å›åˆ° pytestApi ç›®å½•
        self.data_dir = project_root / 'data' / env
        
        # æ£€æŸ¥æ•°æ®ç›®å½•æ˜¯å¦å­˜åœ¨
        if not self.data_dir.exists():
            print(f"âš ï¸  è­¦å‘Š: æ•°æ®ç›®å½•ä¸å­˜åœ¨ {self.data_dir}")
            print(f"    è¯·ç¡®ä¿åœ¨ data/ ç›®å½•ä¸‹æœ‰ {env} æ–‡ä»¶å¤¹")
    
    def scan_files(self) -> List[Path]:
        """
        æ‰«æå¯ç”¨çš„æµ‹è¯•æ–‡ä»¶
        :return: æ–‡ä»¶åˆ—è¡¨
        """
        if not self.data_dir.exists():
            return []
        
        files = list(self.data_dir.glob('*.xlsx'))
        # è¿‡æ»¤æ‰ä¸´æ—¶æ–‡ä»¶ (~$å¼€å¤´çš„æ–‡ä»¶) å’Œéšè—æ–‡ä»¶
        files = [f for f in files if not f.name.startswith('~$') and not f.name.startswith('.')]
        # æŒ‰æ–‡ä»¶åæ’åº
        files.sort(key=lambda x: x.name)
        
        return files
    
    def _parse_selection(self, choice: str, files: List[Path]) -> List[Path]:
        """
        è§£æç”¨æˆ·çš„é€‰æ‹©è¾“å…¥
        æ”¯æŒæ ¼å¼ï¼š1,3,5-8,10
        """
        selected = []
        parts = choice.split(',')
        
        for part in parts:
            part = part.strip()
            if '-' in part:
                # èŒƒå›´é€‰æ‹©: 5-8
                try:
                    start, end = map(int, part.split('-'))
                    for i in range(start, end + 1):
                        if 1 <= i <= len(files):
                            selected.append(files[i - 1])
                except ValueError:
                    print(f"âš ï¸  å¿½ç•¥æ— æ•ˆèŒƒå›´: {part}")
            else:
                # å•ä¸ªé€‰æ‹©: 3
                try:
                    idx = int(part)
                    if 1 <= idx <= len(files):
                        selected.append(files[idx - 1])
                    else:
                        print(f"âš ï¸  å¿½ç•¥è¶…å‡ºèŒƒå›´çš„ç¼–å·: {idx}")
                except ValueError:
                    print(f"âš ï¸  å¿½ç•¥æ— æ•ˆè¾“å…¥: {part}")
        
        # å»é‡å¹¶ä¿æŒé¡ºåº
        seen = set()
        result = []
        for f in selected:
            if f not in seen:
                seen.add(f)
                result.append(f)
        
        return result
    
    def _select_by_group(self, files: List[Path]) -> List[Path]:
        """æŒ‰ä¸šåŠ¡æ¨¡å—åˆ†ç»„é€‰æ‹©"""
        # ä¸šåŠ¡æ¨¡å—åˆ†ç»„é…ç½®
        groups = {
            'ç”¨æˆ·ç®¡ç†': ['ç”¨æˆ·ç®¡ç†.xlsx'],
            'è®¢å•ç®¡ç†': ['è®¢å•ç®¡ç†.xlsx', 'è®¢å•å›æ”¶ç«™.xlsx', 'è´­ç‰©è½¦ç®¡ç†.xlsx'],
            'å•†å“ç®¡ç†': ['å•†å“ç®¡ç†.xlsx', 'é€šç”¨å•†å“.xlsx', 'äº§å“ç®¡ç†.xlsx'],
            'æ’ä»¶ç®¡ç†': [
                'æ’ä»¶ç®¡ç†åŠèµ„æºä¸­å¿ƒæ’ä»¶.xlsx', 'ä¼˜æƒ ç æ’ä»¶.xlsx', 
                'å®åæ’ä»¶.xlsx', 'å·¥å•æ’ä»¶.xlsx', 'æç°æ’ä»¶.xlsx', 'é€€æ¬¾æ’ä»¶.xlsx'
            ],
            'ç³»ç»Ÿç®¡ç†': ['ç³»ç»Ÿè®¾ç½®.xlsx', 'ç®¡ç†å‘˜è®¾ç½®.xlsx', 'ä¸Šä¸‹æ¸¸ç®¡ç†.xlsx'],
            'èµ„æºç®¡ç†': ['å¼¹æ€§IP.xlsx', 'ç£ç›˜.xlsx', 'DCIM.xlsx', 'è‡ªå®šä¹‰äº‘.xlsx'],
            'è´¢åŠ¡ç®¡ç†': ['å‘ç¥¨.xlsx'],
            'APIç®¡ç†': ['APIç®¡ç†.xlsx'],
        }
        
        print("\n" + "="*60)
        print("ğŸ“¦ ä¸šåŠ¡æ¨¡å—åˆ†ç»„")
        print("="*60)
        
        # åªæ˜¾ç¤ºå½“å‰ç›®å½•ä¸­å­˜åœ¨çš„åˆ†ç»„
        available_groups = {}
        for idx, (group_name, group_files) in enumerate(groups.items(), 1):
            # æ£€æŸ¥è¿™ä¸ªåˆ†ç»„æ˜¯å¦æœ‰æ–‡ä»¶å­˜åœ¨
            existing_files = [f for f in files if f.name in group_files]
            if existing_files:
                available_groups[idx] = (group_name, existing_files)
                print(f"  [{idx}] {group_name} ({len(existing_files)} ä¸ªæ–‡ä»¶)")
        
        if not available_groups:
            print("  æš‚æ— å¯ç”¨çš„ä¸šåŠ¡æ¨¡å—åˆ†ç»„")
            return []
        
        print("="*60)
        choice = input("\nè¯·é€‰æ‹©ä¸šåŠ¡æ¨¡å—ç¼–å· (æ”¯æŒå¤šé€‰ï¼Œå¦‚: 1,3,5): ").strip()
        
        if not choice:
            return []
        
        selected = []
        for part in choice.split(','):
            try:
                idx = int(part.strip())
                if idx in available_groups:
                    _, group_files = available_groups[idx]
                    selected.extend(group_files)
            except ValueError:
                print(f"âš ï¸  å¿½ç•¥æ— æ•ˆè¾“å…¥: {part}")
        
        return selected
    
    def interactive_select(self) -> List[Path]:
        """
        äº¤äº’å¼é€‰æ‹©ç•Œé¢
        :return: ç”¨æˆ·é€‰æ‹©çš„æ–‡ä»¶åˆ—è¡¨
        """
        files = self.scan_files()
        
        if not files:
            print("âŒ æœªæ‰¾åˆ°ä»»ä½•æµ‹è¯•æ–‡ä»¶")
            return []
        
        print("\n" + "="*60)
        print(f"ğŸ“‚ å¯ç”¨æµ‹è¯•æ–‡ä»¶åˆ—è¡¨ (ç¯å¢ƒ: {self.env})")
        print("="*60)
        
        # æ˜¾ç¤ºæ–‡ä»¶åˆ—è¡¨
        for idx, file in enumerate(files, 1):
            # æ˜¾ç¤ºæ–‡ä»¶å¤§å°ï¼ˆå¯é€‰ï¼‰
            size_kb = file.stat().st_size / 1024
            print(f"  [{idx:2d}] {file.name:<45s} ({size_kb:.1f} KB)")
        
        print("\n" + "="*60)
        print("é€‰æ‹©æ–¹å¼:")
        print("  1. è¾“å…¥æ–‡ä»¶ç¼–å· (ä¾‹å¦‚: 1,3,5-8)")
        print("  2. è¾“å…¥ 'all' é€‰æ‹©å…¨éƒ¨")
        print("  3. è¾“å…¥ 'group' æŒ‰ä¸šåŠ¡æ¨¡å—é€‰æ‹©")
        print("  4. ç›´æ¥å›è½¦å–æ¶ˆ")
        print("="*60)
        
        choice = input("\nè¯·é€‰æ‹©: ").strip()
        
        if not choice:
            return []
        elif choice.lower() == 'all':
            print(f"\nâœ… å·²é€‰æ‹©å…¨éƒ¨ {len(files)} ä¸ªæ–‡ä»¶")
            return files
        elif choice.lower() == 'group':
            return self._select_by_group(files)
        else:
            return self._parse_selection(choice, files)


class ConcurrentExecutor:
    """å¹¶å‘æ‰§è¡Œå¼•æ“"""
    
    def __init__(self, max_workers: int = None, current_dir: str = None):
        """
        åˆå§‹åŒ–å¹¶å‘æ‰§è¡Œå¼•æ“
        :param max_workers: æœ€å¤§å¹¶å‘æ•°ï¼ŒNone è¡¨ç¤ºè‡ªåŠ¨æ£€æµ‹ CPU æ ¸å¿ƒæ•°
        :param current_dir: å½“å‰å·¥ä½œç›®å½•
        """
        self.max_workers = max_workers or os.cpu_count()
        self.current_dir = current_dir or os.getcwd()
        self.results_base_dir = Path(current_dir) / 'TestReport' / 'temp_results'
        
        # ç¡®ä¿ä¸´æ—¶ç»“æœç›®å½•å­˜åœ¨
        self.results_base_dir.mkdir(parents=True, exist_ok=True)
    
    def execute_single_file(self, file_info: tuple) -> Dict[str, Any]:
        """
        æ‰§è¡Œå•ä¸ªæ–‡ä»¶çš„æµ‹è¯•
        :param file_info: (æ–‡ä»¶è·¯å¾„, worker_id) å…ƒç»„
        :return: æ‰§è¡Œç»“æœå­—å…¸
        """
        file_path, worker_id = file_info
        
        # ä¸ºæ¯ä¸ªæ–‡ä»¶åˆ›å»ºç‹¬ç«‹çš„ç»“æœç›®å½•
        result_dir = self.results_base_dir / f'worker_{worker_id}'
        result_dir.mkdir(parents=True, exist_ok=True)
        
        # è®¾ç½®ç¯å¢ƒå˜é‡
        env = os.environ.copy()
        env['TEST_DATA_FILE'] = str(file_path)
        env['ALLURE_RESULTS_DIR'] = str(result_dir)
        env['WORKER_ID'] = str(worker_id)  # ç”¨äºæ—¥å¿—éš”ç¦»
        # ğŸ”§ è®¾ç½® Python è¾“å‡ºç¼–ç ä¸º UTF-8ï¼Œé¿å… GBK ç¼–ç é”™è¯¯ï¼ˆç‰¹åˆ«æ˜¯ emoji å­—ç¬¦ï¼‰
        env['PYTHONIOENCODING'] = 'utf-8'
        
        # æ„å»º pytest å‘½ä»¤
        test_file = Path(self.current_dir) / 'test_case' / 'test_case.py'
        cmd = [
            sys.executable, '-m', 'pytest',
            str(test_file),
            '-s', '-q',
            '--clean-alluredir',
            f'--alluredir={result_dir}',
            '--tb=short',  # çŸ­æ ¼å¼çš„é”™è¯¯ä¿¡æ¯
        ]
        
        print(f"\nğŸš€ å¼€å§‹æ‰§è¡Œ: {file_path.name} (Worker {worker_id})")
        
        start_time = time.time()
        try:
            result = subprocess.run(
                cmd, 
                env=env, 
                capture_output=True, 
                text=True,
                encoding='utf-8',  # ğŸ”§ æ˜ç¡®æŒ‡å®š UTF-8 ç¼–ç ï¼Œé¿å… Windows é»˜è®¤ GBK ç¼–ç å¯¼è‡´çš„ emoji é”™è¯¯
                errors='replace',  # é‡åˆ°æ— æ³•è§£ç çš„å­—ç¬¦æ—¶ç”¨æ›¿æ¢å­—ç¬¦ä»£æ›¿ï¼Œé¿å…å´©æºƒ
                cwd=self.current_dir,
                timeout=600  # 10åˆ†é’Ÿè¶…æ—¶
            )
            end_time = time.time()
            
            return {
                'file': file_path.name,
                'file_path': str(file_path),
                'worker_id': worker_id,
                'result_dir': result_dir,
                'return_code': result.returncode,
                'duration': end_time - start_time,
                'stdout': result.stdout,
                'stderr': result.stderr,
                'success': result.returncode == 0,
                'error': None
            }
            
        except subprocess.TimeoutExpired:
            end_time = time.time()
            return {
                'file': file_path.name,
                'file_path': str(file_path),
                'worker_id': worker_id,
                'result_dir': result_dir,
                'return_code': -1,
                'duration': end_time - start_time,
                'stdout': '',
                'stderr': 'Execution timeout (600s)',
                'success': False,
                'error': 'Timeout'
            }
            
        except Exception as e:
            end_time = time.time()
            return {
                'file': file_path.name,
                'file_path': str(file_path),
                'worker_id': worker_id,
                'result_dir': result_dir,
                'return_code': -1,
                'duration': end_time - start_time,
                'stdout': '',
                'stderr': str(e),
                'success': False,
                'error': str(e)
            }
    
    def execute_concurrent(self, file_list: List[Path]) -> List[Dict[str, Any]]:
        """
        å¹¶å‘æ‰§è¡Œå¤šä¸ªæ–‡ä»¶
        :param file_list: è¦æ‰§è¡Œçš„æ–‡ä»¶åˆ—è¡¨
        :return: æ‰§è¡Œç»“æœåˆ—è¡¨
        """
        if not file_list:
            print("âŒ æ–‡ä»¶åˆ—è¡¨ä¸ºç©º")
            return []
        
        print(f"\n{'='*60}")
        print(f"ğŸš€ å¯åŠ¨å¹¶å‘æ‰§è¡Œå¼•æ“")
        print(f"{'='*60}")
        print(f"   ğŸ“Š æ–‡ä»¶æ•°: {len(file_list)}")
        print(f"   âš™ï¸  å¹¶å‘æ•°: {self.max_workers}")
        print(f"   ğŸ“ ç»“æœç›®å½•: {self.results_base_dir}")
        print(f"{'='*60}\n")
        
        results = []
        
        # å‡†å¤‡ä»»åŠ¡åˆ—è¡¨ï¼š(æ–‡ä»¶è·¯å¾„, worker_id)
        tasks = [(file, idx) for idx, file in enumerate(file_list)]
        
        # ä½¿ç”¨è¿›ç¨‹æ± æ‰§è¡Œ
        with ProcessPoolExecutor(max_workers=self.max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_file = {
                executor.submit(self.execute_single_file, task): task[0]
                for task in tasks
            }
            
            # ç­‰å¾…ä»»åŠ¡å®Œæˆ
            completed = 0
            total = len(future_to_file)
            
            for future in as_completed(future_to_file):
                file = future_to_file[future]
                try:
                    result = future.result()
                    results.append(result)
                    
                    completed += 1
                    
                    # æ˜¾ç¤ºè¿›åº¦å’Œç»“æœ
                    status = "âœ… é€šè¿‡" if result['success'] else "âŒ å¤±è´¥"
                    print(f"\n[{completed}/{total}] {status} | {result['file']:<45s} | "
                          f"è€—æ—¶: {result['duration']:.2f}s")
                    
                    # å¦‚æœå¤±è´¥ï¼Œæ˜¾ç¤ºé”™è¯¯ä¿¡æ¯
                    if not result['success'] and result.get('error'):
                        print(f"         âš ï¸  é”™è¯¯: {result['error']}")
                    
                except Exception as e:
                    print(f"\nâŒ {file.name} æ‰§è¡Œå¼‚å¸¸: {e}")
                    results.append({
                        'file': file.name,
                        'file_path': str(file),
                        'success': False,
                        'error': str(e),
                        'duration': 0
                    })
        
        print(f"\n{'='*60}")
        print(f"âœ… å¹¶å‘æ‰§è¡Œå®Œæˆ")
        print(f"{'='*60}\n")
        
        return results


class ReportAggregator:
    """Allure æŠ¥å‘Šèšåˆå™¨"""
    
    def __init__(self, report_dir: str, results_dirs: List[Path]):
        """
        åˆå§‹åŒ–æŠ¥å‘Šèšåˆå™¨
        :param report_dir: æœ€ç»ˆæŠ¥å‘Šç›®å½•
        :param results_dirs: æ‰€æœ‰ allure-results ç›®å½•åˆ—è¡¨
        """
        self.report_dir = Path(report_dir)
        self.results_dirs = results_dirs
        self.merged_results_dir = self.report_dir.parent / 'allure-results'
    
    def merge_results(self) -> bool:
        """
        åˆå¹¶æ‰€æœ‰ allure-results
        :return: æ˜¯å¦æˆåŠŸ
        """
        print("\nğŸ“Š æ­£åœ¨åˆå¹¶æµ‹è¯•ç»“æœ...")
        
        try:
            # æ¸…ç©ºå¹¶åˆ›å»ºåˆå¹¶ç›®å½•
            if self.merged_results_dir.exists():
                shutil.rmtree(self.merged_results_dir)
            self.merged_results_dir.mkdir(parents=True, exist_ok=True)
            
            # å¤åˆ¶æ‰€æœ‰ç»“æœæ–‡ä»¶
            total_files = 0
            for result_dir in self.results_dirs:
                if result_dir.exists():
                    for file in result_dir.glob('*'):
                        if file.is_file():
                            # ç¡®ä¿æ–‡ä»¶åå”¯ä¸€ï¼ˆé¿å…è¦†ç›–ï¼‰
                            dest_file = self.merged_results_dir / file.name
                            counter = 1
                            while dest_file.exists():
                                stem = file.stem
                                suffix = file.suffix
                                dest_file = self.merged_results_dir / f"{stem}_{counter}{suffix}"
                                counter += 1
                            
                            shutil.copy2(file, dest_file)
                            total_files += 1
            
            print(f"   âœ… å·²åˆå¹¶ {total_files} ä¸ªç»“æœæ–‡ä»¶")
            return True
            
        except Exception as e:
            print(f"   âŒ åˆå¹¶ç»“æœå¤±è´¥: {e}")
            return False
    
    def generate_report(self) -> bool:
        """
        ç”Ÿæˆ Allure æŠ¥å‘Š
        :return: æ˜¯å¦æˆåŠŸ
        """
        print("\nğŸ“ˆ æ­£åœ¨ç”Ÿæˆ Allure æŠ¥å‘Š...")
        
        try:
            cmd = f'allure generate {self.merged_results_dir} -o {self.report_dir} --clean'
            result = os.system(cmd)
            
            if result == 0:
                print(f"   âœ… æŠ¥å‘Šç”ŸæˆæˆåŠŸ!")
                print(f"   ğŸ“ æŠ¥å‘Šä½ç½®: {self.report_dir}")
                return True
            else:
                print("   âŒ æŠ¥å‘Šç”Ÿæˆå¤±è´¥!")
                print("   è¯·ç¡®ä¿å·²å®‰è£… Allure å‘½ä»¤è¡Œå·¥å…·")
                return False
                
        except Exception as e:
            print(f"   âŒ ç”ŸæˆæŠ¥å‘Šæ—¶å‡ºé”™: {e}")
            return False
    
    def generate_summary(self, execution_results: List[Dict[str, Any]]) -> None:
        """
        ç”Ÿæˆæ‰§è¡Œæ‘˜è¦
        :param execution_results: æ‰§è¡Œç»“æœåˆ—è¡¨
        """
        total = len(execution_results)
        success = sum(1 for r in execution_results if r.get('success', False))
        failed = total - success
        total_time = sum(r.get('duration', 0) for r in execution_results)
        avg_time = total_time / total if total > 0 else 0
        
        print("\n" + "="*60)
        print("ğŸ“Š æ‰§è¡Œæ‘˜è¦")
        print("="*60)
        print(f"  ğŸ“¦ æ€»æ–‡ä»¶æ•°: {total}")
        print(f"  âœ… æˆåŠŸ: {success}")
        print(f"  âŒ å¤±è´¥: {failed}")
        print(f"  ğŸ“ˆ æˆåŠŸç‡: {(success/total*100):.1f}%")
        print(f"  â±ï¸  æ€»è€—æ—¶: {total_time:.2f}s ({total_time/60:.1f} åˆ†é’Ÿ)")
        print(f"  ğŸš€ å¹³å‡è€—æ—¶: {avg_time:.2f}s/æ–‡ä»¶")
        
        # å¦‚æœæœ‰å¤±è´¥çš„æ–‡ä»¶ï¼Œåˆ—å‡ºæ¥
        if failed > 0:
            print(f"\n  âš ï¸  å¤±è´¥çš„æ–‡ä»¶:")
            for result in execution_results:
                if not result.get('success', False):
                    error_msg = result.get('error', 'æœªçŸ¥é”™è¯¯')
                    print(f"     âŒ {result['file']}: {error_msg}")
        
        print("="*60)


class LogMerger:
    """æ—¥å¿—åˆå¹¶å·¥å…·"""
    
    @staticmethod
    def merge_logs(log_dir: Path, output_file: Path) -> bool:
        """
        åˆå¹¶æ‰€æœ‰ worker çš„æ—¥å¿—åˆ°ç»Ÿä¸€æ–‡ä»¶
        :param log_dir: æ—¥å¿—ç›®å½•
        :param output_file: è¾“å‡ºæ–‡ä»¶
        :return: æ˜¯å¦æˆåŠŸ
        """
        try:
            print("\nğŸ“ æ­£åœ¨åˆå¹¶æ—¥å¿—æ–‡ä»¶...")
            
            # æŸ¥æ‰¾æ‰€æœ‰æ—¥å¿—æ–‡ä»¶
            log_files = []
            if log_dir.exists():
                # æŸ¥æ‰¾æ ¼å¼: log.worker_0, log.worker_1, etc.
                log_files = sorted(log_dir.glob('log.worker_*'))
            
            if not log_files:
                print("   â„¹ï¸  æœªæ‰¾åˆ°éœ€è¦åˆå¹¶çš„æ—¥å¿—æ–‡ä»¶")
                return True
            
            # è¯»å–æ‰€æœ‰æ—¥å¿—æ¡ç›®
            all_entries = []
            for log_file in log_files:
                try:
                    with open(log_file, 'r', encoding='utf-8') as f:
                        entries = f.readlines()
                        all_entries.extend(entries)
                except Exception as e:
                    print(f"   âš ï¸  è¯»å–æ—¥å¿—æ–‡ä»¶ {log_file.name} å¤±è´¥: {e}")
            
            # æŒ‰æ—¶é—´æˆ³æ’åºï¼ˆå¦‚æœæ—¥å¿—æœ‰æ—¶é—´æˆ³çš„è¯ï¼‰
            # è¿™é‡Œç®€å•åœ°æŒ‰åŸé¡ºåºåˆå¹¶ï¼Œå¦‚æœéœ€è¦æ’åºå¯ä»¥è§£ææ—¶é—´æˆ³
            
            # å†™å…¥åˆå¹¶åçš„æ—¥å¿—
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(f"{'='*80}\n")
                f.write(f"åˆå¹¶æ—¥å¿— - ç”Ÿæˆæ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"æ¥æºæ–‡ä»¶æ•°: {len(log_files)}\n")
                f.write(f"{'='*80}\n\n")
                
                for log_file in log_files:
                    f.write(f"\n{'='*80}\n")
                    f.write(f"æ¥æº: {log_file.name}\n")
                    f.write(f"{'='*80}\n")
                    
                    try:
                        with open(log_file, 'r', encoding='utf-8') as lf:
                            f.write(lf.read())
                            f.write("\n")
                    except Exception as e:
                        f.write(f"è¯»å–å¤±è´¥: {e}\n")
           
            print(f"   âœ… æ—¥å¿—å·²åˆå¹¶åˆ°: {output_file}")
            print(f"   ğŸ“Š åˆå¹¶äº† {len(log_files)} ä¸ªæ—¥å¿—æ–‡ä»¶")
            
            return True
            
        except Exception as e:
            print(f"   âŒ åˆå¹¶æ—¥å¿—å¤±è´¥: {e}")
            return False


# æµ‹è¯•ä»£ç 
if __name__ == '__main__':
    print("å¹¶å‘æ‰§è¡Œæ¨¡å—æµ‹è¯•")
    print("="*60)
    
    # æµ‹è¯•æ–‡ä»¶é€‰æ‹©å™¨
    selector = FileSelector('v10')
    files = selector.scan_files()
    print(f"æ‰¾åˆ° {len(files)} ä¸ªæµ‹è¯•æ–‡ä»¶")
    for f in files[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
        print(f"  - {f.name}")

